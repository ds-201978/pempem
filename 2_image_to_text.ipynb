{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Detect text in images and save as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add json credential file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "from shutil import copyfile\n",
    "import re\n",
    "import itertools\n",
    "from google.cloud import vision\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google vision credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_file = '' # LINK TO JSON CREDENTIAL FILE\n",
    "with open(cred_file) as f:\n",
    "    creds = json.load(f)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = cred_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect text in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    '''use Google vision API to detect text from image\n",
    "    only returns raw text, not coordinates of text content'''\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.types.Image(content=content)\n",
    "    response = client.text_detection(image=image)\n",
    "    response = MessageToDict(response, preserving_proto_field_name = True)\n",
    "    try:\n",
    "        response = response['full_text_annotation']['text']\n",
    "    except:\n",
    "        response = ''\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each mill: detect text in images and save content as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_content(mill, ids=None):\n",
    "    '''detect and save text from images as json\n",
    "    if ids are specified, only save image content corresponding to these IDs\n",
    "    otherwise save content for all images of this mill'''\n",
    "    directory = '../Images/weight_receipt'\n",
    "    mill_directory = directory +'/'+mill\n",
    "    if mill+'_text_contents.json' in os.listdir(directory):\n",
    "        with open(directory+'/'+mill+'_text_contents.json') as f:\n",
    "            text_contents = json.load(f)\n",
    "    else:\n",
    "        text_contents = {}\n",
    "    all_images = [file for file in os.listdir(mill_directory) if file.endswith('.jpg')]\n",
    "    if ids:\n",
    "        all_images = [image for image in all_images if image.split('_')[0] in ids]\n",
    "    for image in all_images:\n",
    "        if image.endswith('weight_receipt.jpg'):\n",
    "            image_list = image.split('_')\n",
    "            ID = image_list[0]\n",
    "            if ID not in text_contents.keys():\n",
    "                print('detecting text content of image', ID)\n",
    "                text_image = detect_text(mill_directory+'/'+image)\n",
    "                text_contents[ID] = text_image\n",
    "            else:\n",
    "                print('image', ID, 'already processed')\n",
    "    with open(directory+'/'+mill+'_text_contents.json', 'w') as outfile:\n",
    "        json.dump(text_contents, outfile)\n",
    "    print('Done\\n')\n",
    "    return text_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run image recognition algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_recognition(mill, ids=None):\n",
    "    '''run image recognition algorithm and save content in json format'''\n",
    "    directory = '../Images/weight_receipt/'\n",
    "    all_images = [file for file in os.listdir(directory+mill) if file.endswith('.jpg')]\n",
    "    if not ids:\n",
    "        ids = [image.split('_')[0] for image in all_images]\n",
    "    res_all = save_content(mill, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run recognition for five chosen mills: arvena, bss, nhr, skip and srjnad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['arvena', 'bss', 'nhr', 'skip', 'srjnad']\n",
    "for mill in folders:\n",
    "    print('Processing mill '+mill)\n",
    "    path = '../Images/weight_receipt/'+mill\n",
    "    files = os.listdir(path)\n",
    "    files = [file for file in files if file.endswith('.jpg')]\n",
    "    ids = [file.split('_')[0] for file in files]\n",
    "    run_recognition(mill, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save date and time when images were uploaded to the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Images/weight_receipt'\n",
    "mills = ['arvena', 'bss', 'nhr', 'skip', 'srjnad']\n",
    "mills = [path+'/'+mill for mill in mills]\n",
    "cols = ['ID', 'Date created', 'Time created']\n",
    "df_upload = pd.DataFrame([], columns=cols)\n",
    "for mill in mills:\n",
    "    files = os.listdir(mill)\n",
    "    files = [file for file in files if file.endswith('.jpg')]\n",
    "    df = pd.DataFrame([], columns=cols)\n",
    "    df['ID'] = [int(file.split('_')[0]) for file in files]\n",
    "    dates = [file.split('_')[3] for file in files]\n",
    "    df['Date created'] = [datetime.strptime(date, '%y%m%d').strftime('%m/%d/%Y') for date in dates]\n",
    "    times = [file.split('_')[4] for file in files]\n",
    "    df['Time created'] = [datetime.strptime(time, '%H%M').strftime('%H:%M') for time in times]\n",
    "    df_upload = pd.concat([df_upload, df], sort=False)\n",
    "df_upload.to_csv(path+'/'+'date_time_upload.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
