{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3 - Parsing of text to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "from shutil import copyfile\n",
    "import re\n",
    "import itertools\n",
    "from google.cloud import vision\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing algorithms for each mill\n",
    "Input: Raw text in string format  \n",
    "Output: list of date, entry and exit times and weights  \n",
    "One algorithm per mill because of the variability of receipt layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_skip(text):\n",
    "    res = []\n",
    "    dates = re.findall('[0-9]{1,2}\\/[0-9]{1,2}\\/[0-9]{4}', text)\n",
    "    try:\n",
    "        date = dates[0]\n",
    "        date = datetime.strptime(date, '%d/%m/%Y').strftime('%m/%d/%Y') # convert to American date format\n",
    "    except:\n",
    "        date = ''\n",
    "    res.append(date)\n",
    "    times = re.findall('[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}|[0-9]{1,2}\\.[0-9]{1,2}\\:[0-9]{1,2}|[0-9]{1,2}\\.[0-9]{1,2}\\.[0-9]{1,2}|[0-9]{1,2}\\:[0-9]{1,2}\\.[0-9]{1,2}', text)\n",
    "    try:\n",
    "        entry_time = times[0].replace('.',':')\n",
    "    except IndexError:\n",
    "        entry_time =''\n",
    "    try:\n",
    "        exit_time = times[1].replace('.',':')\n",
    "    except IndexError:\n",
    "        exit_time = ''\n",
    "    res.append(entry_time)\n",
    "    res.append(exit_time)\n",
    "    weights = re.findall('\\d+\\.\\d+ kg|\\d+ kg|\\d+\\.\\d+ 1g|\\d+ 1g|\\d+\\.\\d+ ko|\\d+ ko', text)\n",
    "    weights = [int(w.replace('.','').replace(' kg','').replace(' 1g','').replace(' ko','')) for w in weights]\n",
    "    while len(weights) < 5:\n",
    "        weights.append('')\n",
    "    res += weights\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_nhr(text):\n",
    "    res = []\n",
    "    dates = re.findall('[0-9]{1,2}\\/[0-9]{1,2}\\/[0-9]{4}', text)\n",
    "    try:\n",
    "        date = dates[0]\n",
    "        try:\n",
    "            date = datetime.strptime(date, '%d/%m/%Y').strftime('%m/%d/%Y') # convert to American date format\n",
    "        except ValueError:\n",
    "            pass\n",
    "    except IndexError:\n",
    "        date = ''\n",
    "    res.append(date)\n",
    "    times = re.findall('\\d+\\:\\d+\\:\\d+', text)\n",
    "    try:\n",
    "        entry_time = times[0]\n",
    "    except IndexError:\n",
    "        entry_time =''\n",
    "    try:\n",
    "        exit_time = times[1]\n",
    "    except IndexError:\n",
    "        exit_time = ''\n",
    "    res.append(entry_time)\n",
    "    res.append(exit_time)\n",
    "    weights = re.findall('\\d+\\,[0-9]{3}|\\d+\\.\\[0-9]{3}', text)\n",
    "    try:\n",
    "        first_weight = weights[0]\n",
    "        text = text.replace(':','')\n",
    "        text_list = text.split('\\n')\n",
    "        idx = text_list.index(first_weight)\n",
    "        weights = text_list[idx:idx+5]\n",
    "        weights = [w.replace('.','').replace(',','') for w in weights]\n",
    "        weights = [w for w in weights if w.isdigit()]\n",
    "        weights = [int(w) for w in weights]\n",
    "    except IndexError:\n",
    "        pass\n",
    "    while len(weights) < 5:\n",
    "        weights.append('')\n",
    "    res += weights\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_arvena(text):\n",
    "    res = []\n",
    "    dates = re.findall('[0-9]{1,2}\\-[0-9]{1,2}\\-[0-9]{4}', text)\n",
    "    try:\n",
    "        date = dates[0]\n",
    "        date = datetime.strptime(date, '%d-%m-%Y').strftime('%m/%d/%Y') # convert to American date format\n",
    "    except:\n",
    "        date = ''\n",
    "    res.append(date)\n",
    "    times = re.findall('[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}|[0-9]{1,2}\\.[0-9]{1,2}\\:[0-9]{1,2}|[0-9]{1,2}\\.[0-9]{1,2}\\.[0-9]{1,2}|[0-9]{1,2}\\:[0-9]{1,2}\\.[0-9]{1,2}', text)\n",
    "    times = [time[1:] if time[0]=='0' else time for time in times]\n",
    "    try:\n",
    "        entry_time = times[0].replace('.',':')\n",
    "    except IndexError:\n",
    "        entry_time =''\n",
    "    try:\n",
    "        exit_time = times[1].replace('.',':')\n",
    "    except IndexError:\n",
    "        exit_time = ''\n",
    "    res.append(entry_time)\n",
    "    res.append(exit_time)\n",
    "    weights = re.findall('\\d+\\ \\d+ Kg|\\d+ Kg|\\d+\\ \\d+ kg|\\d+ kg', text)\n",
    "    weights = [int(w.replace('.','').replace('Kg','').replace('kg','').replace(' ','')) for w in weights]\n",
    "    try:\n",
    "        potongan = int(re.findall('\\n[0-9]{3}\\n', text)[0].replace('\\n', ''))\n",
    "    except:\n",
    "        potongan = ''\n",
    "    while len(weights) < 4:\n",
    "        weights.append('')\n",
    "    weights = weights[1:3] + [weights[0]] + [potongan] + [weights[3]]\n",
    "    res += weights\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_bss(text):\n",
    "    res = []\n",
    "    dates = re.findall('[0-9]{1,2}\\-[0-9]{1,2}\\-[0-9]{4}', text)\n",
    "    try:\n",
    "        date = dates[0]\n",
    "        date = datetime.strptime(date, '%d-%m-%Y').strftime('%m/%d/%Y') # convert to American date format\n",
    "    except IndexError:\n",
    "        date = ''\n",
    "    res.append(date)\n",
    "    times = re.findall('[0-9]{1,2}\\:[0-9]{1,2}\\:[0-9]{1,2}', text)\n",
    "    times = [time[1:] if time[0]=='0' else time for time in times]\n",
    "    try:\n",
    "        entry_time = times[0].replace('.',':')\n",
    "    except IndexError:\n",
    "        entry_time =''\n",
    "    try:\n",
    "        exit_time = times[1].replace('.',':')\n",
    "    except IndexError:\n",
    "        exit_time = ''\n",
    "    res.append(entry_time)\n",
    "    res.append(exit_time)\n",
    "    weights = re.findall('\\d+\\,[0-9]{3}|\\d+\\.[0-9]{3}', text)\n",
    "    try:\n",
    "        potongan = re.findall('\\n[0-9]{3} G|\\n[0-9]{3} Ko|\\n[0-9]{3} ng|\\n[0-9]{3} K', text)[-1].replace(' G', '').replace(' Ko', '').replace(' ng', '').replace(' K', '').replace('\\n', '')\n",
    "    except:\n",
    "        try:\n",
    "            potongan = re.findall('\\n[0-9]{3}\\n', text)[0].replace('\\n', '')\n",
    "        except:\n",
    "            potongan = ''\n",
    "    while len(weights) < 4:\n",
    "        weights.append('')\n",
    "    weights = [w.replace('.','').replace(' kg','').replace(',','') for w in weights]\n",
    "    weights = weights[:3] + [potongan] + [weights[3]]\n",
    "    weights = [int(w) if w!='' else np.nan for w in weights]\n",
    "    weights.sort()\n",
    "    if np.nan not in weights:\n",
    "        weights = [weights[i] for i in [4,1,3,0,2]]\n",
    "    else:\n",
    "        weights = [weights[3]] + [weights[4]] + [weights[2]] + [weights[0]] + [weights[1]]\n",
    "    while len(weights) < 5:\n",
    "        weights.append('')\n",
    "    res += weights\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_srjnad(text):\n",
    "    res = []\n",
    "    dates = re.findall('[0-9]{1,2}\\/[0-9a-zA-Z]{1,2}\\/[0-9]{4}|[0-9]{1,2}\\/[0-9]{1,2}[1]{1}[0-9]{4}', text)\n",
    "    try:\n",
    "        date = dates[0]\n",
    "        if date[3] == 'D':\n",
    "            date = date[:3] + '0' + date[4:]\n",
    "        if date[-5] == '1':\n",
    "            date = date[:-5] + '/' + date[-4:]\n",
    "        try:\n",
    "            date = datetime.strptime(date, '%d/%m/%Y').strftime('%m/%d/%Y') # convert to American date format\n",
    "        except:\n",
    "            date = ''\n",
    "    except IndexError:\n",
    "        date = ''\n",
    "    res.append(date)\n",
    "    res.append('')\n",
    "    res.append('')\n",
    "    weights = re.findall('\\d+\\,[0-9]{3} Kg|[0-9]{3} Kg', text)\n",
    "    weights = [int(w.replace(',','').replace(' Kg','')) for w in weights]\n",
    "    if len(weights) == 6:\n",
    "        weights = weights[1:]\n",
    "    if len(weights) < 5 and len(weights) > 2:\n",
    "        weights = weights[:3] + [''] + [weights[-1]]\n",
    "    while len(weights) < 5:\n",
    "        weights.append('')\n",
    "    res += weights\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_mapping = {'arvena': parsing_arvena,\n",
    "                    'bss': parsing_bss,\n",
    "                    'nhr': parsing_nhr,\n",
    "                    'skip': parsing_skip,\n",
    "                    'srjnad': parsing_srjnad}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read json files, extract information and create tables for each mill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(mill, ids=None):\n",
    "    '''extracts IDs, users and text contents for this mill\n",
    "    if ids are specified, only extracts these indices, otherwise extracts all available content'''\n",
    "    directory = '../Images/weight_receipt/'\n",
    "    all_images = [file for file in os.listdir(directory+mill) if file.endswith('.jpg')]\n",
    "    if not ids:\n",
    "        ids = [image.split('_')[0] for image in all_images]\n",
    "    users = []\n",
    "    for ID in ids:\n",
    "        for image in all_images:\n",
    "            if image.split('_')[0] == ID:\n",
    "                users.append(image.split('_')[1])\n",
    "    with open(directory+'/'+mill+'_text_contents.json') as f:\n",
    "        text_contents = json.load(f)\n",
    "    return ids, users, text_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save table containing mill, ID, user, date, entry time, exit time and five weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2539 not found in json file nhr\n",
      "3671 not found in json file nhr\n",
      "1907 not found in json file skip\n",
      "3061 not found in json file skip\n",
      "3223 not found in json file skip\n",
      "3319 not found in json file srjnad\n"
     ]
    }
   ],
   "source": [
    "mills = ['arvena', 'bss', 'nhr','skip', 'srjnad']\n",
    "for mill in mills:\n",
    "    ids, users, all_texts = extract_json(mill)\n",
    "    col_names = ['Mill', 'ID', 'User (middle man)', 'Date', 'Entry time', 'Exit time',\n",
    "                 'First weight', 'Second weight', 'Net 1', 'Potongan', 'Net 2']\n",
    "    df_mill_algo = pd.DataFrame([], columns = col_names)\n",
    "    for ID, user in zip(ids, users):\n",
    "        try:\n",
    "            text = all_texts[ID]\n",
    "            res = [mill, ID, user]\n",
    "            res += function_mapping[mill](text)\n",
    "            df_mill_algo.loc[len(df_mill_algo)] = res\n",
    "        except:\n",
    "            print(ID, 'not found in json file', mill)\n",
    "    df_mill_algo.to_csv('../Images/weight_receipt/Algo '+mill+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results of algorithm to csv for all mills\n",
    "Aggregate tables for all mills into one table  \n",
    "Only use the entry time as the reference time  \n",
    "Remove seconds from times  \n",
    "Include date and time of receipt upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mill</th>\n",
       "      <th>ID</th>\n",
       "      <th>User (middle man)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>First weight</th>\n",
       "      <th>Second weight</th>\n",
       "      <th>Net 1</th>\n",
       "      <th>Potongan</th>\n",
       "      <th>Net 2</th>\n",
       "      <th>Date created</th>\n",
       "      <th>Time created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>nhr</td>\n",
       "      <td>9</td>\n",
       "      <td>dwisuyanto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10130.0</td>\n",
       "      <td>5605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/05/2018</td>\n",
       "      <td>15:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>srjnad</td>\n",
       "      <td>14</td>\n",
       "      <td>madyani</td>\n",
       "      <td>12/04/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11820.0</td>\n",
       "      <td>3910.0</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>7630.0</td>\n",
       "      <td>12/05/2018</td>\n",
       "      <td>19:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>srjnad</td>\n",
       "      <td>16</td>\n",
       "      <td>madyani</td>\n",
       "      <td>12/05/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9150.0</td>\n",
       "      <td>3890.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>12/05/2018</td>\n",
       "      <td>20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>nhr</td>\n",
       "      <td>20</td>\n",
       "      <td>dwisuyanto</td>\n",
       "      <td>12/06/2018</td>\n",
       "      <td>15:09</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>4320.0</td>\n",
       "      <td>7110.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>6754.0</td>\n",
       "      <td>12/06/2018</td>\n",
       "      <td>15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>skip</td>\n",
       "      <td>23</td>\n",
       "      <td>aguswibowo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/07/2018</td>\n",
       "      <td>15:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>arvena</td>\n",
       "      <td>5719</td>\n",
       "      <td>muhammadfahrirambe</td>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>10:48</td>\n",
       "      <td>6070.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>8970.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>12:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>srjnad</td>\n",
       "      <td>5721</td>\n",
       "      <td>sudiwarnopandiangan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>15:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>skip</td>\n",
       "      <td>5723</td>\n",
       "      <td>sumaji</td>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>19:09</td>\n",
       "      <td>10290.0</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>6630.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>6298.0</td>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>15:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>skip</td>\n",
       "      <td>5728</td>\n",
       "      <td>madyani</td>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>16:29</td>\n",
       "      <td>12200.0</td>\n",
       "      <td>3910.0</td>\n",
       "      <td>8290.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>7875.0</td>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>19:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>srjnad</td>\n",
       "      <td>5732</td>\n",
       "      <td>safrizal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/07/2019</td>\n",
       "      <td>19:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2533 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mill    ID    User (middle man)        Date   Time  First weight  \\\n",
       "570      nhr     9           dwisuyanto         NaN    NaN       10130.0   \n",
       "1842  srjnad    14              madyani  12/04/2018    NaN       11820.0   \n",
       "1861  srjnad    16              madyani  12/05/2018    NaN        9150.0   \n",
       "240      nhr    20           dwisuyanto  12/06/2018  15:09       11430.0   \n",
       "995     skip    23           aguswibowo         NaN    NaN           NaN   \n",
       "...      ...   ...                  ...         ...    ...           ...   \n",
       "161   arvena  5719   muhammadfahrirambe  09/07/2019  10:48        6070.0   \n",
       "2470  srjnad  5721  sudiwarnopandiangan         NaN    NaN           NaN   \n",
       "1614    skip  5723               sumaji  09/07/2019  19:09       10290.0   \n",
       "1615    skip  5728              madyani  09/07/2019  16:29       12200.0   \n",
       "2471  srjnad  5732             safrizal         NaN    NaN           NaN   \n",
       "\n",
       "      Second weight   Net 1  Potongan   Net 2 Date created Time created  \n",
       "570          5605.0     NaN       NaN     NaN   12/05/2018        15:37  \n",
       "1842         3910.0  7910.0     280.0  7630.0   12/05/2018        19:56  \n",
       "1861         3890.0  5260.0       NaN  5050.0   12/05/2018        20:00  \n",
       "240          4320.0  7110.0     356.0  6754.0   12/06/2018        15:35  \n",
       "995             NaN     NaN       NaN     NaN   12/07/2018        15:27  \n",
       "...             ...     ...       ...     ...          ...          ...  \n",
       "161          2900.0  8970.0     520.0     0.0   09/07/2019        12:56  \n",
       "2470            NaN     NaN       NaN     NaN   09/07/2019        15:23  \n",
       "1614         3660.0  6630.0     332.0  6298.0   09/07/2019        15:58  \n",
       "1615         3910.0  8290.0     415.0  7875.0   09/07/2019        19:09  \n",
       "2471            NaN     NaN       NaN     NaN   09/07/2019        19:20  \n",
       "\n",
       "[2533 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upload = pd.read_csv('../Images/weight_receipt/date_time_upload.csv', index_col=0)\n",
    "mills = ['arvena', 'bss', 'nhr','skip', 'srjnad']\n",
    "col_names = ['Mill', 'ID', 'User (middle man)', 'Date', 'Entry time', 'Exit time',\n",
    "                 'First weight', 'Second weight', 'Net 1', 'Potongan', 'Net 2']\n",
    "df_all_mills = pd.DataFrame([], columns = col_names)\n",
    "for mill in mills:\n",
    "    df = pd.read_csv('../Images/weight_receipt/Algo '+mill+'.csv', index_col=0)\n",
    "    df['Mill'] = mill\n",
    "    df_all_mills = pd.concat([df_all_mills, df], sort=False)\n",
    "df_all_mills['ID'] = df_all_mills['ID'].apply(lambda x: str(x))\n",
    "df_upload['ID'] = df_upload['ID'].apply(lambda x: str(x))\n",
    "df_all_mills = df_all_mills.merge(df_upload, on='ID')\n",
    "def rm_sec(x):\n",
    "    try:\n",
    "        return x[:-3]\n",
    "    except:\n",
    "        return x\n",
    "df_all_mills['Entry time'] = df_all_mills['Entry time'].apply(lambda x: rm_sec(x))\n",
    "df_all_mills['Exit time'] = df_all_mills['Exit time'].apply(lambda x: rm_sec(x))\n",
    "df_all_mills = df_all_mills.drop(columns=['Exit time']).rename(columns={'Entry time':'Time'})\n",
    "df_all_mills['ID'] = df_all_mills['ID'].apply(lambda x: int(x))\n",
    "df_all_mills = df_all_mills.sort_values(by=['ID'])\n",
    "df_all_mills.to_csv('../Images/weight_receipt/Algo all mills.csv', index=False)\n",
    "df_all_mills"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
