{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Scraping receipts from PemPem website and saving them as images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add pempem username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import urllib.request\n",
    "import os.path\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(ID):\n",
    "    '''login and scrape text from pempem website for given ID'''\n",
    "    # login\n",
    "    session_requests = requests.session()\n",
    "    payload = {'username': '', 'password': ''} # USERNAME and PASSWORD\n",
    "    login_url = 'https://backend.pempemapp.org/login'\n",
    "    result = session_requests.get(login_url)\n",
    "    tree = html.fromstring(result.text)\n",
    "    authenticity_token = list(set(tree.xpath(\"//input[@name='_token']/@value\")))[0]\n",
    "    payload['_token'] = authenticity_token\n",
    "    result = session_requests.post(login_url, data = payload, headers = dict(referer=login_url))\n",
    "    \n",
    "    # scraping\n",
    "    url = 'https://backend.pempemapp.org/receipt/' + ID\n",
    "    res = session_requests.get(url, headers = dict(referer = url))\n",
    "    if 'ErrorException' in res.text:\n",
    "        return None\n",
    "    else:\n",
    "        return res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(scraped_text):\n",
    "    '''extract relevant information from scraped text as dictionary including receipt type'''\n",
    "    dic = {}\n",
    "    parsed_html = BeautifulSoup(scraped_text)\n",
    "    table = parsed_html.find('table',attrs={'class':'table table-striped'})\n",
    "    try:\n",
    "        trs = table.find_all('tr')\n",
    "        for tr in trs:\n",
    "            th = tr.find('th').text\n",
    "            td = tr.find('td')\n",
    "            if th == 'Price Receipt' or th == 'Weight Receipt':\n",
    "                link = td.find('a')\n",
    "                if link:\n",
    "                    dic['receipt_type'] = th\n",
    "                    dic[th] = link['href']\n",
    "            else:\n",
    "                dic[th] = td.text\n",
    "    except:\n",
    "        pass\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(dic):\n",
    "    '''save image from pempem website in folder Images/weight_receipt or Images/price_receipt\n",
    "    file name format: ID_middleManName_millName_dateUpload_receiptType.jpg'''\n",
    "    receipt_type = dic['receipt_type'] # 'Price Receipt' or 'Weight Receipt'\n",
    "    image_url = dic[receipt_type]\n",
    "    ID = dic['Id'][:-1]\n",
    "    middle_man_name = dic['User Name'].replace('/','').replace(' ','').lower()\n",
    "    mill_name = dic['Mill Name'].replace('/','').replace(' ','').lower()\n",
    "    if mill_name=='':\n",
    "        mill_name = 'no_mill_name'\n",
    "    date = datetime.strptime(dic['Created At'], '%d %b %Y %I:%M %p').strftime('%y%m%d_%H%M')\n",
    "    receipt_type_name = receipt_type.replace(' ','_').lower()\n",
    "    if not os.path.exists('../Images'):\n",
    "        os.mkdir('../Images')\n",
    "    receipt_type_folder = '../Images/'+receipt_type_name\n",
    "    if not os.path.exists(receipt_type_folder):\n",
    "        os.mkdir(receipt_type_folder)\n",
    "    folder_name = receipt_type_folder+'/'+mill_name\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    file_name = folder_name+'/'+ID+'_'+middle_man_name+'_'+mill_name+'_'+date+'_'+receipt_type_name+'.jpg'\n",
    "    if not os.path.exists(file_name):\n",
    "        urllib.request.urlretrieve(image_url, file_name)\n",
    "        print('Saved new image file for ID ' + ID+'/mill '+mill_name)\n",
    "    else:\n",
    "        print('Image for ID '+ID+'/mill '+mill_name+' is already saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(startId, lastId):\n",
    "    '''run scraping and save images in folders for all IDs between startId and lastId'''\n",
    "    for ID in range(startId, lastId+1):\n",
    "        print('Processing ID', ID)\n",
    "        scraped_text = scraping(str(ID))\n",
    "        if scraped_text:\n",
    "            dic = parsing(scraped_text)\n",
    "            if dic:\n",
    "                save_image(dic)\n",
    "            else:\n",
    "                print('ID '+str(ID)+' not found')\n",
    "        else:\n",
    "            print('ID '+str(ID)+' not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "startId = 0\n",
    "lastId = 5732\n",
    "run(startId, lastId)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
